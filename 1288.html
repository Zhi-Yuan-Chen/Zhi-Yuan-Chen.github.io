<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>HGCN论文模型代码follow | 贝尔摩德</title><meta name="author" content="noionion"><meta name="copyright" content="noionion"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1、摘要 论文解决的问题是什么？   In this paper, we study the problemof heterogeneous graph-enhanced relational learning for recom-mendation.   在推荐系统里面解决异构图增强学习  框架的理解：  Heterogeneous Graph Contrastive Learning (HGC"><meta property="og:type" content="article"><meta property="og:title" content="HGCN论文模型代码follow"><meta property="og:url" content="https://noionion.top/1288.html"><meta property="og:site_name" content="贝尔摩德"><meta property="og:description" content="1、摘要 论文解决的问题是什么？   In this paper, we study the problemof heterogeneous graph-enhanced relational learning for recom-mendation.   在推荐系统里面解决异构图增强学习  框架的理解：  Heterogeneous Graph Contrastive Learning (HGC"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://noionion-picture-bed.oss-cn-hangzhou.aliyuncs.com/deemo_for_cover/4.png"><meta property="article:published_time" content="2023-10-28T12:51:39.000Z"><meta property="article:modified_time" content="2023-10-28T12:51:39.000Z"><meta property="article:author" content="noionion"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://noionion-picture-bed.oss-cn-hangzhou.aliyuncs.com/deemo_for_cover/4.png"><link rel="shortcut icon" href="https://noionion-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/head.jpg"><link rel="canonical" href="https://noionion.top/1288"><link rel="preconnect" href="//cdn1.tianli0.top"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdnjs.sourcegcdn.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:void 0,noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,source:{jQuery:"https://cdnjs.sourcegcdn.com/ajax/libs/jquery/3.6.0/jquery.min.js",justifiedGallery:{js:"https://cdnjs.sourcegcdn.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js",css:"https://cdnjs.sourcegcdn.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"},fancybox:{js:"https://cdnjs.sourcegcdn.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js",css:"https://cdnjs.sourcegcdn.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"}},isPhotoFigcaption:!0,islazyload:!1,isanchor:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-10-28 20:51:39"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,o){0!==o&&(o=864e5*o,t={value:t,expiry:(new Date).getTime()+o},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=a=>new Promise((t,e)=>{const o=document.createElement("script");o.src=a,o.async=!0,o.onerror=e,o.onload=o.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(o.onload=o.onreadystatechange=null,t())},document.head.appendChild(o)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme");"dark"===e?activateDarkMode():"light"===e&&activateLightMode()})(window)</script><link rel="stylesheet" href="https://cdn1.tianli0.top/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css"><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"Jws8lO85zPmXkSKj",ck:"Jws8lO85zPmXkSKj"})</script><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="贝尔摩德" type="application/atom+xml"><link rel="alternate" href="/rss.xml" title="贝尔摩德" type="application/rss+xml"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="simply-cha-top"></div><div class="is-center" id="sidebar-avatar"><div class="avatar-img"><img src="https://noionion-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/head.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">noionion</div><div class="author-info__description">欢迎光临！</div></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">5</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/2X-ercha"><i class="fab fa-github"></i><span> Follow Me</span></a><div class="menu-info-social-icons is-center"><a class="social-icon" href="https://github.com/Zhi-Yuan-Chen" target="_blank" title="Github"><i class="fa-fw fab fa-github"></i></a><a class="social-icon" href="mailto:noionion@outlook.com" target="_blank" title="Email"><i class="fa-fw fas fa-envelope"></i></a><a class="social-icon" href="/rss.xml" target="_blank" title="rss"><i class="fa-fw fas fa-rss"></i></a></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua1"></use></svg><span>甜瓜待摘</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-45px"><li><a class="site-page child" href="/tags/Course/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-jiaocheng"></use></svg><span>教程分享</span></a></li><li><a class="site-page child" href="/tags/Project/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangmu"></use></svg><span>自制项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-miao"></use></svg><span>种瓜日记</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-100px"><li><a class="site-page child" href="/tags/C/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-colorful-code"></use></svg><span>搓搓C++</span></a></li><li><a class="site-page child" href="/tags/Python/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-colorful-code"></use></svg><span>玩玩爬虫</span></a></li><li><a class="site-page child" href="/tags/html/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-colorful-code"></use></svg><span>摸摸前端</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-tea"></use></svg><span>生活日常</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-100px"><li><a class="site-page child" href="/link/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-pengyou"></use></svg><span>友情链接</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://memos.noionion.cn/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-pengyouquanzhushou2x"></use></svg><span>随便说说</span></a></li><li><a class="site-page child" href="/messageboard/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuoshuo-"></use></svg><span>留言信箱</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-liuyan"></use></svg><span>猹的哔哔</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-45px"><li><a class="site-page child" href="/tags/Diary/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-tubiaozhizuomoban-"></use></svg><span>贰猹随笔</span></a></li><li><a class="site-page child" href="/about/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xinfeng"></use></svg><span>猹的自述</span></a></li></ul></div></div><div class="simply-cha"></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/">贝尔摩德</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua1"></use></svg><span>甜瓜待摘</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-45px"><li><a class="site-page child" href="/tags/Course/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-jiaocheng"></use></svg><span>教程分享</span></a></li><li><a class="site-page child" href="/tags/Project/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangmu"></use></svg><span>自制项目</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-miao"></use></svg><span>种瓜日记</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-100px"><li><a class="site-page child" href="/tags/C/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-colorful-code"></use></svg><span>搓搓C++</span></a></li><li><a class="site-page child" href="/tags/Python/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-colorful-code"></use></svg><span>玩玩爬虫</span></a></li><li><a class="site-page child" href="/tags/html/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-colorful-code"></use></svg><span>摸摸前端</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-tea"></use></svg><span>生活日常</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-100px"><li><a class="site-page child" href="/link/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-pengyou"></use></svg><span>友情链接</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://memos.noionion.cn/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-pengyouquanzhushou2x"></use></svg><span>随便说说</span></a></li><li><a class="site-page child" href="/messageboard/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuoshuo-"></use></svg><span>留言信箱</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-liuyan"></use></svg><span>猹的哔哔</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child" style="left:-45px"><li><a class="site-page child" href="/tags/Diary/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-tubiaozhizuomoban-"></use></svg><span>贰猹随笔</span></a></li><li><a class="site-page child" href="/about/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xinfeng"></use></svg><span>猹的自述</span></a></li></ul></div></div></div><div id="navFn"><div id="search-button"><a class="social-icon search"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-sousuo"></use></svg><span>搜索</span></a></div><div id="darkmodeBt"><a class="darkmode switch"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-deng1"></use></svg><span id="darkmode-switch">关灯</span></a></div><div id="toggle-menu"><a class="site-page"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mulu"></use></svg></a></div></div></div></nav></header><div id="mainbody"><div id="content_leftside"><div id="left_menu"><div class="leftside-social"><a class="social-icon" href="https://github.com/Zhi-Yuan-Chen" target="_blank" title="Github"><i class="fa-fw fab fa-github"></i></a><a class="social-icon" href="mailto:noionion@outlook.com" target="_blank" title="Email"><i class="fa-fw fas fa-envelope"></i></a><a class="social-icon" href="/rss.xml" target="_blank" title="rss"><i class="fa-fw fas fa-rss"></i></a></div><div class="leftside-contents"><span id="read-percent">0</span></div><div class="leftside-comment"><a href="#post-comment" title="要去留言吗？"><i class="fa-lg fas fa-comment"></i></a></div><div class="leftside-qq" title="来糖果屋聊天噻！"><i class="fa-lg fas fa-qrcode"></i></div><div class="leftside-rmb"><a title="柿还在施工的捐赠页！不给看！"><i class="fa-lg fas fa-money-check-dollar"></i></a></div></div><div id="left_display"><div class="candy_qrcode"><img src="./img/candy-qr.png"></div></div></div><main class="layout hide-aside" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">HGCN论文模型代码follow</h1><div id="post-meta"><div class="tag-cloud-list is-center"></div><div class="meta-firstline"><span class="post-meta-date"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rili"></use></svg><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-10-28T12:51:39.000Z" title="发表于 2023-10-28 20:51:39">2023-10-28</time><span class="post-meta-separator">|</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shijian"></use></svg><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-10-28T12:51:39.000Z" title="更新于 2023-10-28 20:51:39">2023-10-28</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="HGCN论文模型代码follow"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div><div class="line"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg></div></div></div><article class="post-content" id="article-container"><h2 id="1、摘要"><a href="#1、摘要" class="headerlink" title="1、摘要"></a>1、摘要</h2><ul><li>论文解决的问题是什么？</li></ul><blockquote><p>In this paper, we study the problem<br>of heterogeneous graph-enhanced relational learning for recom-<br>mendation.</p></blockquote><p>在推荐系统里面解决异构图增强学习</p><ul><li>框架的理解：</li></ul><p>Heterogeneous Graph Contrastive Learning (HGCL)：异构图对比学习</p><p>①这个框架可以能够将异构关系语义合并到结合到用户-项目交互建模中</p><p>②鉴于异构边信息<code>heterogeneous side information</code>在用户和物品不同，使用元网络<code>meta networks</code>增强异构图对比学习，以允许具有自适应对比增强的个性化知识转换器</p><ul><li>实验效果：</li></ul><blockquote><p>The experimental results on three real-world datasets<br>demonstrate the superiority of HGCL over state-of-the-art recom-<br>mendation methods. Through ablation study, key components in<br>HGCL method are validated to benefit the recommendation perfor-<br>mance improvement. The source code of the model implementation<br>is available at the link <a target="_blank" rel="noopener" href="https://github.com/HKUDS/HGCL">https://github.com/HKUDS/HGCL</a>.</p></blockquote><p>在三个数据集上进行了研究，比最先进的<code>state-of-the-art</code>推荐系统的方法好。</p><p>并且进行了消融实验。消融实验的理解：</p><p>:::primary<br>消融研究对于深度学习研究至关重要。理解系统中的因果关系是产生可靠知识的最直接方式（任何研究的目标）。消融是一种非常省力的方式来研究因果关系。<br>如果您采用任何复杂的深度学习实验设置，您可能会删除一些模块（或用随机的模块替换一些训练有素的功能）而不会降低性能。消除研究过程中的噪音：进行消融研究。<br>如果您无法完全理解您的系统？很多活动部件，想确定它的工作原因是否与您的假设密切相关？尝试删除东西。花费至少约10％的实验时间来诚实地反驳你的论文。<br>:::</p><h2 id="2、介绍-INTRODUCTION"><a href="#2、介绍-INTRODUCTION" class="headerlink" title="2、介绍(INTRODUCTION)"></a>2、介绍(INTRODUCTION)</h2><p>①GNN在推荐系统里面编码用户和商品的关系中大放异彩，关键思想是通过聚合图传播层上的邻居的特征信息来学习节点表示(节点包括<code>user</code>和<code>item</code>)。但是现在很多基于<code>GNN</code>的协同过滤模型<code>collaborative filtering (CF) models</code>仅关注同质信息。HGCL解决了这个问题。</p><p>②当前大部分的异构图神经网络受到了稀疏训练标签的限制，即目前的异构图神经网络对标签很敏感，可能会因此没法产生高质量的<code>user/item embeddings</code>,用于模型优化。所以引入了图对比自监督学习<code>Contrastive self-supervised learning</code>,GCL可以有效解决缺乏足够观察标签的问题。GCL的核心思想：正对比样本的表示之间的一致性将被最大化，而负对的嵌入之间的距离将被推开(<del>应该是最小化的意思？</del>)。</p><p>③边信息之间的依赖关系和用户-物品交互建模往往不是单一的，而是具有多样性的。本文学习了一个对比增强器<code>contrastive augmentor</code></p><p>本文实质上要解决的问题：</p><ul><li>如何有效地跨不同视图迁移辅助知识</li><li>如何通过个性化增强进行异构关系对比学习</li></ul><p>进入框架：</p><ol><li>利用<code>异质图神经网络</code>作为编码器，在编码嵌入中保留了异质关系的丰富语义。</li><li>为了应对个性化增强，我们提出了一个定制的对比学习框架，该框架设计了一个<code>元网络</code>来编码用户和项目的个性化特征。它允许我们执行特定于用户和项目的增强，以跨不同的关系视图传递信息信号。</li></ol><p><del>怎么感觉这篇论文像把别人的工作缝合起来就变成了自己的工作捏</del></p><h2 id="3、相关的工作"><a href="#3、相关的工作" class="headerlink" title="3、相关的工作"></a>3、相关的工作</h2><h3 id="3-1-基于gnn的推荐系统"><a href="#3-1-基于gnn的推荐系统" class="headerlink" title="3.1 基于gnn的推荐系统"></a>3.1 基于gnn的推荐系统</h3><h3 id="3-2-推荐系统中的对比学习"><a href="#3-2-推荐系统中的对比学习" class="headerlink" title="3.2 推荐系统中的对比学习"></a>3.2 推荐系统中的对比学习</h3><p>对比自监督学习生成的自监督信号可以用来丰富用户表示学习。在推荐系统中，对比学习可以成为一个强大的工具，将自监督信号与对比表示视图之间的对齐结合起来进行数据增强。</p><h3 id="3-3-异构图学习"><a href="#3-3-异构图学习" class="headerlink" title="3.3 异构图学习"></a>3.3 异构图学习</h3><h2 id="4、方法"><a href="#4、方法" class="headerlink" title="4、方法"></a>4、方法</h2><p>ok，进入框架的具体部分咯</p><p><img src="https://s2.loli.net/2023/07/25/yrbAMeiN3cOn7pC.png" alt="毕设图片1.png"></p><h4 id="4-1-符号表示"><a href="#4-1-符号表示" class="headerlink" title="4.1 符号表示"></a>4.1 符号表示</h4><ul><li>用户-商品图：$\mathcal{G} _{ui}={\mathcal{V} _u,\mathcal{V} _i,\mathcal{E} _{ui}}$</li></ul><p>$\mathcal{V} _u$:用户集合</p><p>$\mathcal{V} _i$:物品集合</p><p>$\mathcal{E}_{\mathcal{U}\boldsymbol{i}}$:边的集合，里面的边说明用户u和物品i有过互动</p><ul><li>用户-用户图：$G_{uu}={\mathcal{V}<em>{u},\mathcal{E}</em>{uu}}$</li></ul><p>$\mathcal{E}_{\mathcal{u}\boldsymbol{u}}$:里面的边说明两个用户有过互动</p><ul><li>物品-物品图：$G_{ii}={\mathcal{V}<em>{i},\mathcal{E}</em>{ii}}$</li></ul><p>$\mathcal{E}_{\mathcal{i}\boldsymbol{i}}$:里面的边说明两个物品在外部知识里面有联系(比如属于同一类物品)</p><p>三个邻接矩阵:$\mathbf{A}<em>{ui}\in\mathbb{R}^{m\times n},\mathbf{A}</em>{uu}\in\mathbb{R}^{m\times m},\mathbf{A}_{ii}\in\mathbb{R}^{n\times n}$。</p><p>这个图就要用来预测用户和物品之间未观察到的交互</p><h4 id="4-2-异构图关系学习"><a href="#4-2-异构图关系学习" class="headerlink" title="4.2 异构图关系学习"></a>4.2 异构图关系学习</h4><h5 id="4-2-1-关系感知embedding初始化"><a href="#4-2-1-关系感知embedding初始化" class="headerlink" title="4.2.1 关系感知embedding初始化"></a>4.2.1 关系感知embedding初始化</h5><ol><li><p>使用<code>xavier initializer</code>对id-corresponding embeddings $\mathbf{e}_u,\mathbf{e}_i\in\mathbb{R}^d$进行初始化，d代表隐藏的维度,代码如下：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 初始化权重,hide_dim是隐藏层深度，为d</span><br><span class="line">def init_weight(self, userNum, itemNum, hide_dim):</span><br><span class="line">    initializer &#x3D; nn.init.xavier_uniform_</span><br><span class="line">    embedding_dict &#x3D; nn.ParameterDict(&#123;</span><br><span class="line">        &#39;user_emb&#39;: nn.Parameter(initializer(t.empty(userNum, hide_dim))),</span><br><span class="line">        &#39;item_emb&#39;: nn.Parameter(initializer(t.empty(itemNum, hide_dim))),</span><br><span class="line">    &#125;)</span><br><span class="line">    return embedding_dict</span><br></pre></td></tr></table></figure><p>代码解读：</p><ul><li>这段代码是一个类的方法，用于初始化权重。它接受三个参数：<code>userNum</code>表示用户数量，<code>itemNum</code>表示物品数量，<code>hide_dim</code>表示隐藏层的维度（或深度）。</li><li>在方法内部，首先创建了一个<code>nn.ParameterDict</code>对象来存储权重参数。<code>nn.ParameterDict</code>是PyTorch中的一种数据结构，用于保存一组参数。参数被定义为<code>nn.Parameter</code>对象，并使用指定的初始化器进行初始化。</li><li>在这里，使用了Xavier均匀分布初始化器<code>nn.init.xavier_uniform_</code>，它会根据指定的形状生成均匀分布的随机数，并将其作为参数的初始值。</li><li>最后，方法返回了这个<code>embedding_dict</code>对象，它将在模型的其他部分使用到初始化权重。</li></ul><p>在主要模型里面，代码体现在：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Initialize Embeddings</span></span><br><span class="line">userembed0 = self.embedding_dict[<span class="string">&#x27;user_emb&#x27;</span>].weight</span><br><span class="line">itemembed0 = self.embedding_dict[<span class="string">&#x27;item_emb&#x27;</span>].weight</span><br></pre></td></tr></table></figure></li><li><p>特定于节点的embedding(<code>node-specific embeddings</code>)形成了初始的<code>embedding</code>矩阵$\mathbf{E}_{\boldsymbol{u}}^0\in\mathbb{R}^{\boldsymbol{m}\times d}$和$\mathbf{E}_i^0\in\mathbb{R}^{\boldsymbol{n}\times\boldsymbol{d}}$,这两个初始的矩阵分别被送入了不同的图编码器， user-item域， user-user域，item-item域。</p></li><li><p>为了突出这三种关系类型之间交互模式的差异，训练了一个自门控模块去派生出用户社会联系和物品语义联系的关系感知嵌入(<code>relation-aware embeddings</code>),公式如下：$$\mathbf{E}<em>{uu}^0=\mathbf{E}_u^0\odot\sigma(\mathbf{E}_u^0\mathbf{W}_g+\mathbf{b}_g);\quad\mathbf{E}</em>{ii}^0=\mathbf{E}_i^0\odot\sigma(\mathbf{E}_i^0\mathbf{W}_g+\mathbf{b}_g)$$</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用户的relation-aware embeddings</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">self_gatingu</span>(<span class="params">self,em</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.multiply(em, torch.sigmoid(torch.matmul(em,self.gating_weightu) + self.gating_weightub))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 物品语义联系的relation-aware embeddings</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">self_gatingi</span>(<span class="params">self,em</span>):</span></span><br><span class="line">    <span class="keyword">return</span> torch.multiply(em, torch.sigmoid(torch.matmul(em,self.gating_weighti) + self.gating_weightib))</span><br></pre></td></tr></table></figure><p>其中$\mathbf{E}_\text{uu }^0\in\mathbb{R}^{m\times d}$代表同构图${\mathcal{G}}<em>\text{uu}$的embedding，$\mathbf{E}</em>{ii}^0\in\mathbb{R}^{\boldsymbol{n}\times d}$代表同构图${\mathcal{G}}_\text{ii}$的embedding。σ(i)代表<code>sigmoid</code>激活函数，⊙ 表示逐元素乘法运算。通过这个乘法跳跃连接的自门机制，$\mathbf{E}_\text{uu }^0$,$\mathbf{E}_\text{ii}^0$不仅与初始的embedding共享共同语义，同时在表现user-user和item-item关系方面也更加灵活</p></li></ol><p>在主要模型里面，代码内容体现在：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过self_gatingu和self_gatingi对它们进行自门控处理，得到uu_embed0和ii_embed0</span></span><br><span class="line">uu_embed0  = self.self_gatingu(userembed0)</span><br><span class="line">ii_embed0  = self.self_gatingi(itemembed0)</span><br><span class="line"><span class="comment"># 将userembed0和itemembed0连接起来，得到ui_embeddings</span></span><br><span class="line">self.ui_embeddings       = t.cat([ userembed0, itemembed0], <span class="number">0</span>)</span><br></pre></td></tr></table></figure><h5 id="4-2-2-异质消息传播"><a href="#4-2-2-异质消息传播" class="headerlink" title="4.2.2 异质消息传播"></a>4.2.2 异质消息传播</h5><ol><li>首先应用图卷积神经网络作为图结构三视图的编码器。以用户-物品关系图为例详细阐述建模过程：<ul><li>对于图$\mathcal{G} <em>{ui}$, HGCL迭代细化用户和物品嵌入，如下:$\mathbf{e}<em>u^{l+1}=\sum</em>{i\in\mathcal{N}<em>u}\frac1{\sqrt{|\mathcal{N}_u|}\sqrt{|\mathcal{N}_i|}}\mathbf{e}_i^l;\quad\mathbf{e}_i^{l+1}=\sum</em>{u\in\mathcal{N}_i}\frac1{\sqrt{|\mathcal{N}_i|}\sqrt{|\mathcal{N}_u|}}\mathbf{e}_u^l$,其中$\mathcal{N}</em>{\mathcal{u}}$和$\mathcal{N}_{\mathcal{i}}$代表目标节点u和i的邻居集合。$\mathbf{e}_u^l,\mathbf{e}_i^l\in\mathbb{R}^d$表示在第$l$轮循环中user u和item i的 embedding向量。</li><li>$\mathbf{e}_u^0,\mathbf{e}_i^0$是embedding矩阵$\mathbf{E}_u^0,\mathbf{E}_i^0$的行向量。</li><li>关系感知消息传递范式没有进行转换和非线性激活。</li></ul></li></ol><p>对于<code>GCN</code>图神经网络的定义，如下面代码所示：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GCN_layer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(GCN_layer, self).__init__()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">sparse_mx_to_torch_sparse_tensor</span>(<span class="params">self, sparse_mx</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Convert a scipy sparse matrix to a torch sparse tensor.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 将一个scipy稀疏矩阵转换为torch稀疏张量的形式</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">type</span>(sparse_mx) != sp.coo_matrix:</span><br><span class="line">            sparse_mx = sparse_mx.tocoo().astype(np.float32)</span><br><span class="line">        indices = torch.from_numpy(</span><br><span class="line">            np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))</span><br><span class="line">        values = torch.from_numpy(sparse_mx.data).<span class="built_in">float</span>()</span><br><span class="line">        shape = torch.Size(sparse_mx.shape)</span><br><span class="line">        <span class="keyword">return</span> torch.sparse.FloatTensor(indices, values, shape)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">normalize_adj</span>(<span class="params">self, adj</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Symmetrically normalize adjacency matrix.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 对邻接矩阵进行对称归一化操作</span></span><br><span class="line">        adj = sp.coo_matrix(adj)</span><br><span class="line">        rowsum = np.array(adj.<span class="built_in">sum</span>(<span class="number">1</span>))</span><br><span class="line">        d_inv_sqrt = np.power(rowsum, -<span class="number">0.5</span>).flatten()</span><br><span class="line">        d_inv_sqrt[np.isinf(d_inv_sqrt)] = <span class="number">0.</span></span><br><span class="line">        d_mat_inv_sqrt = sp.diags(d_inv_sqrt)</span><br><span class="line">        <span class="keyword">return</span> (d_mat_inv_sqrt).dot(adj).dot(d_mat_inv_sqrt).tocoo()    </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, features, Mat, index</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;features是节点的特征矩阵</span></span><br><span class="line"><span class="string">        Mat是图的邻接矩阵</span></span><br><span class="line"><span class="string">        index是需要更新的节点索引&quot;&quot;&quot;</span></span><br><span class="line">        subset_Mat = Mat</span><br><span class="line">        subset_features = features</span><br><span class="line">        subset_Mat = self.normalize_adj(subset_Mat)</span><br><span class="line">        subset_sparse_tensor = self.sparse_mx_to_torch_sparse_tensor(subset_Mat).cuda()</span><br><span class="line">        out_features = torch.spmm(subset_sparse_tensor, subset_features)</span><br><span class="line">        new_features = torch.empty(features.shape).cuda()</span><br><span class="line">        new_features[index] = out_features</span><br><span class="line">        dif_index = np.setdiff1d(torch.arange(features.shape[<span class="number">0</span>]), index)</span><br><span class="line">        new_features[dif_index] = features[dif_index]</span><br><span class="line">        <span class="keyword">return</span> new_features</span><br></pre></td></tr></table></figure><p>一、首先先来看这个<code>sparse_mx_to_torch_sparse_tensor</code>函数。</p><p>1、<code>if type(sparse_mx) != sp.coo_matrix: sparse_mx = sparse_mx.tocoo().astype(np.float32)</code>.</p><p>这段代码首先判断判断输入的稀疏矩阵 <code>sparse_mx</code> 的类型是否为 <code>scipy.sparse.coo_matrix</code>，如果不是，则将其转换为 <code>coo_matrix</code> 类</p><p>2、<code>indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))</code></p><p>这段代码的目的是创建一个稀疏矩阵中非零元素的索引张量 <code>indices</code>。</p><p>首先，<code>sparse_mx.row</code> 是稀疏矩阵 <code>sparse_mx</code> 中非零元素所在的行索引数组。<code>sparse_mx.col</code> 是稀疏矩阵 <code>sparse_mx</code> 中非零元素所在的列索引数组。</p><p>接下来，<code>np.vstack((sparse_mx.row, sparse_mx.col))</code> 将行索引和列索引数组按垂直方向进行堆叠，形成一个形状为 <code>(2, nnz)</code> 的数组，其中 <code>nnz</code> 是稀疏矩阵中非零元素的数量。在堆叠后的数组中，第一行是非零元素的行索引，第二行是非零元素的列索引。</p><p>最后，<code>torch.from_numpy</code> 将上述数组转换为 PyTorch 张量 <code>indices</code>。这个张量存储了稀疏矩阵中非零元素的行索引和列索引，每一列对应一个非零元素的位置 <code>(row_index, col_index)</code>。</p><p>二、看看<code>def normalize_adj(self, adj)</code>这段代码</p><p>首先，代码使用 <code>sp.coo_matrix(adj)</code> 将输入的邻接矩阵 <code>adj</code> 转换为 <code>scipy.sparse.coo_matrix</code> 类型的稀疏矩阵。这是为了确保邻接矩阵的表示形式符合 COO 格式的要求。</p><p>接下来，代码计算每个节点的度数（degree）之和 <code>rowsum</code>，即邻接矩阵每一行的元素之和。这里使用 <code>adj.sum(1)</code> 对邻接矩阵的每一行进行求和操作，得到一个形状为 <code>(n, 1)</code> 的数组，其中 <code>n</code> 是节点的数量。</p><p>然后，代码计算每个节点度数的倒数的平方根 <code>d_inv_sqrt</code>，通过对 <code>rowsum</code> 进行 <code>-0.5</code> 次幂运算得到。注意，为避免除以 0 的情况，代码使用 <code>np.isinf</code> 函数将无穷大的元素置为 0。</p><p>然后，代码计算每个节点度数的倒数的平方根 <code>d_inv_sqrt</code>，通过对 <code>rowsum</code> 进行 <code>-0.5</code> 次幂运算得到。注意，为避免除以 0 的情况，代码使用 <code>np.isinf</code> 函数将无穷大的元素置为 0。</p><p>接着，代码构建对角矩阵 <code>d_mat_inv_sqrt</code>，其中对角线元素为 <code>d_inv_sqrt</code>，其余元素为 0。这里使用 <code>sp.diags</code> 函数创建对角矩阵。</p><p>最后，代码执行对称归一化操作，根据公式 <code>D^(-0.5) * A * D^(-0.5)</code>，其中 <code>D</code> 是 <code>d_mat_inv_sqrt</code> 对角矩阵，<code>A</code> 是输入的邻接矩阵。这里使用矩阵乘法 <code>dot</code> 进行计算，并将结果转换为 COO 稀疏矩阵表示形式。</p><p>最终，函数返回对称归一化后的邻接矩阵，以 COO 稀疏矩阵的形式返回。</p><p>三、前向传递<code>forward</code>函数</p><p>这段代码是一个图神经网络的前向传播函数。它接受节点的特征矩阵 <code>features</code>，图的邻接矩阵 <code>Mat</code>，以及需要更新的节点索引 <code>index</code>。</p><ol><li><code>subset_Mat = Mat</code>：将输入的邻接矩阵 <code>Mat</code> 赋值给变量 <code>subset_Mat</code>。</li><li><code>subset_features = features</code>：将输入的节点特征矩阵 <code>features</code> 赋值给变量 <code>subset_features</code>。</li><li><code>subset_Mat = self.normalize_adj(subset_Mat)</code>：调用 <code>self.normalize_adj</code> 函数对 <code>subset_Mat</code> 进行对称归一化操作，得到归一化后的邻接矩阵。</li><li><code>subset_sparse_tensor = self.sparse_mx_to_torch_sparse_tensor(subset_Mat).cuda()</code>：将归一化后的邻接矩阵转换为稀疏张量，并将其移动到 GPU 上。<code>self.sparse_mx_to_torch_sparse_tensor</code> 是一个辅助函数，将稀疏矩阵转换为 PyTorch 中的稀疏张量表示。</li><li><code>out_features = torch.spmm(subset_sparse_tensor, subset_features)</code>：利用稀疏矩阵-稠密矩阵乘法（Sparse Matrix-Dense Matrix Multiplication，<code>spmm</code>）操作，将归一化后的邻接矩阵 <code>subset_sparse_tensor</code> 与节点特征矩阵 <code>subset_features</code> 相乘，得到输出特征 <code>out_features</code>。</li><li><code>new_features = torch.empty(features.shape).cuda()</code>：创建一个与输入特征矩阵 <code>features</code> 相同形状的空张量 <code>new_features</code>，并将其移动到 GPU 上。</li><li><code>new_features[index] = out_features</code>：将输出特征 <code>out_features</code> 赋值给 <code>new_features</code> 的指定索引 <code>index</code>，更新对应节点的特征。</li><li><code>dif_index = np.setdiff1d(torch.arange(features.shape[0]), index)</code>：使用 <code>np.setdiff1d</code> 函数计算出不在索引 <code>index</code> 中的节点索引集合 <code>dif_index</code>。</li><li><code>new_features[dif_index] = features[dif_index]</code>：将输入特征矩阵 <code>features</code> 中不在索引 <code>index</code> 中的节点特征复制到 <code>new_features</code> 中，保持这些节点的特征不变。</li><li><code>return new_features</code>：返回更新后的节点特征矩阵 <code>new_features</code>。</li></ol><p>在主要模型里面，代码体现在：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入编码器的循环，对每个编码器层进行处理。</span></span><br><span class="line"><span class="comment"># 在第一次迭代时，使用初始的uu_embed0、ii_embed0和ui_embeddings作为输入；</span></span><br><span class="line"><span class="comment"># 之后的迭代中，使用前一层的输出作为输入。</span></span><br><span class="line">self.all_user_embeddings = [uu_embed0]</span><br><span class="line">self.all_item_embeddings = [ii_embed0]</span><br><span class="line">self.all_ui_embeddings   = [self.ui_embeddings]</span><br><span class="line"><span class="comment"># Encoder</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.encoder)):</span><br><span class="line">    layer = self.encoder[i]</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:  </span><br><span class="line">        userEmbeddings0 = layer(uu_embed0, self.uuMat, user_index)</span><br><span class="line">        itemEmbeddings0 = layer(ii_embed0, self.iiMat, item_index)</span><br><span class="line">        uiEmbeddings0   = layer(self.ui_embeddings, self.uiMat, ui_index)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        userEmbeddings0 = layer(userEmbeddings, self.uuMat, user_index)</span><br><span class="line">        itemEmbeddings0 = layer(itemEmbeddings, self.iiMat, item_index)</span><br><span class="line">        uiEmbeddings0   = layer(uiEmbeddings,   self.uiMat, ui_index)</span><br></pre></td></tr></table></figure><h5 id="4-2-3-异构信息聚合"><a href="#4-2-3-异构信息聚合" class="headerlink" title="4.2.3 异构信息聚合"></a>4.2.3 异构信息聚合</h5><p>每次迭代中的信息都是从异质关系中聚合而来。</p><ul><li>通过异构消息传播的多次迭代，高阶嵌入通过多跳连接保留异构语义。特别地，user和item的embdding以下定义的异构融合过程进行更新：</li></ul><p>$$\widehat{\mathbf{E}}<em>u^{l+1}=f(\mathbf{E}<em>u^{l+1},\mathbf{E}</em>{uu}^{l+1});\quad\widehat{\mathbf{E}}_i^{l+1}=f(\mathbf{E}_i^{l+1},\mathbf{E}</em>{ii}^{l+1})$$</p><p>第$l$+1轮迭代中的embedding $\widehat{\mathbf{E}}_u^{l+1}\in\mathbb{R}^{m\times d},\widehat{\mathbf{E}_i}^{\boldsymbol{l}+1}\in\mathbb{R}^{\boldsymbol{n}\times d}$整合了异构语义，成为下一层的输入，$f$代表异构信息融合函数，出于降低模型复杂度的考虑，用逐元素均值池化作为融合函数$f(·)$</p><p>代码体现在：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Aggregation of message features across the two related views in the middle layer then fed into the next layer</span></span><br><span class="line"><span class="comment"># 中间层两个相关视图的消息特征聚合，然后输入下一层</span></span><br><span class="line">self.ui_userEmbedding0, self.ui_itemEmbedding0 = t.split(uiEmbeddings0, [self.userNum, self.itemNum])</span><br><span class="line">userEd=( userEmbeddings0 + self.ui_userEmbedding0 )/<span class="number">2.0</span></span><br><span class="line">itemEd=( itemEmbeddings0 + self.ui_itemEmbedding0 )/<span class="number">2.0</span></span><br><span class="line">userEmbeddings=userEd </span><br><span class="line">itemEmbeddings=itemEd</span><br><span class="line">uiEmbeddings=torch.cat([ userEd,itemEd],<span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> norm == <span class="number">1</span>: <span class="comment">#对嵌入向量进行L2范数归一化操作</span></span><br><span class="line">    norm_embeddings = F.normalize(userEmbeddings0, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 将归一化后的嵌入向量分别添加到列表这</span></span><br><span class="line">    self.all_user_embeddings += [norm_embeddings]</span><br><span class="line">    norm_embeddings = F.normalize(itemEmbeddings0, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    self.all_item_embeddings += [norm_embeddings]</span><br><span class="line">    norm_embeddings = F.normalize(uiEmbeddings0, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    self.all_ui_embeddings   += [norm_embeddings]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    self.all_user_embeddings += [userEmbeddings]</span><br><span class="line">    self.all_item_embeddings += [norm_embeddings]</span><br><span class="line">    self.all_ui_embeddings   += [norm_embeddings]</span><br></pre></td></tr></table></figure><ul><li><p>为了用编码的特定层表示进一步聚合异质信息，生成user和item的整体embedding：$$\mathbf{E}<em>u=\mathbf{E}<em>u^0+\sum</em>{l=1}^L\frac{\mathbf{E}_u^l}{||\mathbf{E}_u^l||};\quad\mathbf{E}_i=\mathbf{E}_i^0+\sum</em>{l=1}^L\frac{\mathbf{E}_i^l}{||\mathbf{E}_i^l||}$$,其中$l$代表<code>GCN</code>的最大迭代次数,每个GCN层的输出归一化。使用跳跃连接添加初始嵌入$\mathbf{E}_u^0,\mathbf{E}_i^0$,上述公式表明了用户-项目交互视图的特定层表示聚合。</p><p>代码具体体现在：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.userEmbedding = t.stack(self.all_user_embeddings, dim=<span class="number">1</span>)</span><br><span class="line">self.userEmbedding = t.mean(self.userEmbedding, dim = <span class="number">1</span>)</span><br><span class="line">self.itemEmbedding = t.stack(self.all_item_embeddings, dim=<span class="number">1</span>)  </span><br><span class="line">self.itemEmbedding = t.mean(self.itemEmbedding, dim = <span class="number">1</span>)</span><br><span class="line">self.uiEmbedding   = t.stack(self.all_ui_embeddings, dim=<span class="number">1</span>)</span><br><span class="line">self.uiEmbedding   = t.mean(self.uiEmbedding, dim=<span class="number">1</span>)</span><br><span class="line">self.ui_userEmbedding, self.ui_itemEmbedding = t.split(self.uiEmbedding, [self.userNum, self.itemNum])</span><br></pre></td></tr></table></figure><p>pytorch代码解释：</p><ol><li><code>self.userEmbedding = t.stack(self.all_user_embeddings, dim=1)</code>：将 <code>self.all_user_embeddings</code> 中的嵌入向量按照维度1进行堆叠，得到一个新的张量 <code>self.userEmbedding</code>。这里假设 <code>self.all_user_embeddings</code> 是一个包含多个嵌入向量的列表或张量，维度为 <code>(embedding_dim, num_user_embeddings)</code>。</li><li><code>self.userEmbedding = t.mean(self.userEmbedding, dim=1)</code>：对 <code>self.userEmbedding</code> 进行维度1上的平均池化操作，得到一个平均后的用户嵌入向量。这里假设 <code>self.userEmbedding</code> 是一个维度为 <code>(embedding_dim, num_user_embeddings)</code> 的张量，通过对维度1上的元素求平均，得到一个维度为 <code>(embedding_dim,)</code> 的用户嵌入向量。</li><li><code>self.itemEmbedding = t.stack(self.all_item_embeddings, dim=1)</code>：类似于第一行的操作，将 <code>self.all_item_embeddings</code> 中的嵌入向量按照维度1进行堆叠，得到一个新的张量 <code>self.itemEmbedding</code>。</li><li><code>self.itemEmbedding = t.mean(self.itemEmbedding, dim=1)</code>：类似于第二行的操作，对 <code>self.itemEmbedding</code> 进行维度1上的平均池化操作，得到一个平均后的物品嵌入向量。</li><li><code>self.uiEmbedding = t.stack(self.all_ui_embeddings, dim=1)</code>：类似于第一行的操作，将 <code>self.all_ui_embeddings</code> 中的嵌入向量按照维度1进行堆叠，得到一个新的张量 <code>self.uiEmbedding</code>。</li><li><code>self.uiEmbedding = t.mean(self.uiEmbedding, dim=1)</code>：类似于第二行的操作，对 <code>self.uiEmbedding</code> 进行维度1上的平均池化操作，得到一个平均后的用户-物品组合嵌入向量。</li><li><code>self.ui_userEmbedding, self.ui_itemEmbedding = t.split(self.uiEmbedding, [self.userNum, self.itemNum])</code>：将 <code>self.uiEmbedding</code> 按照给定的索引进行拆分，得到用户嵌入向量和物品嵌入向量。具体来说，<code>self.uiEmbedding</code> 的形状应该为 <code>(embedding_dim, num_ui_embeddings)</code>，其中 <code>num_ui_embeddings</code> 是用户-物品组合的数量。然后，通过 <code>t.split</code> 函数将 <code>self.uiEmbedding</code> 按照索引 <code>[self.userNum, self.itemNum]</code> 进行拆分，得到两个张量 <code>self.ui_userEmbedding</code> 和 <code>self.ui_itemEmbedding</code>，分别表示用户和物品的嵌入向量。</li></ol></li><li><p>user-user和item-item的嵌入是以类似的方式通过多阶信息聚合得到的。</p></li></ul><p>代码也在上面了。</p><h3 id="4-3-跨视图元网络"><a href="#4-3-跨视图元网络" class="headerlink" title="4.3 跨视图元网络"></a>4.3 跨视图元网络</h3><h4 id="4-3-1-元知识提取"><a href="#4-3-1-元知识提取" class="headerlink" title="4.3.1 元知识提取"></a>4.3.1 元知识提取</h4><p>提炼出的用户-用户关系视图和物品-物品关系视图的元知识如下：</p><p>$\mathbf{M}<em>{\boldsymbol{u}\boldsymbol{u}}=\mathbf{E}</em>{\boldsymbol{u}}||\mathbf{E}<em>{\boldsymbol{u}\boldsymbol{u}}||\sum</em>{\boldsymbol{i}\in\mathcal{N}<em>{\boldsymbol{u}}}\mathbf{e}</em>{i};\quad\mathbf{M}<em>{\boldsymbol{i}\boldsymbol{i}}=\mathbf{E}</em>{i}||\mathbf{E}<em>{\boldsymbol{i}\boldsymbol{i}}||\sum</em>{\boldsymbol{u}\in\mathcal{N}<em>{\boldsymbol{i}}}\mathbf{e}</em>{\boldsymbol{u}}$,其中$\mathbf{M}<em>{uu}\in\mathbb{R}^{m\times3d},\mathbf{M}</em>{ii}\in\mathbb{R}^{n\times3d}$表示编码上下文信息的元知识，分别为用户和项目侧知识生成个性化的知识迁移函数。</p><p>除此之外，将邻域信息纳入元知识中。</p><p>辅助域的embedding表征了用户的社会影响力和项目的语义相关性</p><p>具体代码展示如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Meta-knowlege extraction</span></span><br><span class="line"><span class="comment"># 进行元知识提取的过程</span></span><br><span class="line">tembedu=(self.meta_netu(t.cat((auxiembedu,targetembedu,uneighbor),dim=<span class="number">1</span>).detach()))</span><br><span class="line">tembedi=(self.meta_neti(t.cat((auxiembedi,targetembedi,ineighbor),dim=<span class="number">1</span>).detach()))</span><br></pre></td></tr></table></figure><p>代码解读：</p><ol><li><code>tembedu = (self.meta_netu(t.cat((auxiembedu, targetembedu, uneighbor), dim=1).detach()))</code>：该行代码将辅助用户嵌入向量 (<code>auxiembedu</code>)、目标用户嵌入向量 (<code>targetembedu</code>) 和目标用户的邻居信息 (<code>uneighbor</code>) 连接起来，并将连接后的向量作为输入传递给名为 <code>self.meta_netu</code> 的元网络。<code>self.meta_netu</code> 对输入进行处理，得到用户的元嵌入向量 <code>tembedu</code>。<code>detach()</code> 的作用是将输入的梯度信息断开，以避免在元网络的计算过程中对原始输入进行梯度传播。</li></ol><h4 id="4-3-2个性化跨视角知识迁移"><a href="#4-3-2个性化跨视角知识迁移" class="headerlink" title="4.3.2个性化跨视角知识迁移"></a>4.3.2个性化跨视角知识迁移</h4><ul><li>在HGCL中，提取的元知识用于生成具有定制变换矩阵的参数化知识传输网络.所提出的元神经网络是:</li></ul><p>$$\left{\begin{aligned}f_{mlp}^1(\mathbf{M}<em>{uu})&amp;\to\mathbf{W}</em>{uu}^{M1}\f_{mlp}^2(\mathbf{M}<em>{uu})&amp;\to\mathbf{W}</em>{uu}^{M2}\end{aligned}\right.$$</p><p>$f_{mlp}^1,f_{mlp}^1$是元知识学习器，由两个具有 <code>PReLU</code> 激活函数的全连接层组成。这些函数将元知识$M_{uu}$作为输入，输出自定义的transformation矩阵$\mathbf{W}<em>{\boldsymbol{u}\boldsymbol{u}}^{\boldsymbol{M}1}\in\mathbb{R}^{\boldsymbol{m}\times d\times\boldsymbol{k}},\mathbf{W}</em>{\boldsymbol{u}\boldsymbol{u}}^{\boldsymbol{M}2}\in\mathbb{R}^{\boldsymbol{m}\times\boldsymbol{k}\times\boldsymbol{d}}$。两个参数张量都包含 n 个矩阵，每个矩阵为 n 个用户。这两组矩阵将变换的秩限制为$k&lt;d$.</p><p>一、先来看看<code>MLP</code>部分的代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, input_dim, feature_dim, hidden_dim, output_dim,</span></span></span><br><span class="line"><span class="function"><span class="params">                 feature_pre=<span class="literal">True</span>, layer_num=<span class="number">2</span>, dropout=<span class="literal">True</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MLP, self).__init__()</span><br><span class="line">        self.feature_pre = feature_pre</span><br><span class="line">        self.layer_num = layer_num</span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        <span class="keyword">if</span> feature_pre:</span><br><span class="line">            self.linear_pre =   nn.Linear(input_dim, feature_dim,bias=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.linear_first = nn.Linear(input_dim, hidden_dim)</span><br><span class="line">        self.linear_hidden = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(layer_num - <span class="number">2</span>)])</span><br><span class="line">        self.linear_out =    nn.Linear(feature_dim, output_dim,bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data</span>):</span></span><br><span class="line">        x = data</span><br><span class="line">        <span class="keyword">if</span> self.feature_pre:</span><br><span class="line">            x = self.linear_pre(x)</span><br><span class="line">        prelu=nn.PReLU().cuda()</span><br><span class="line">        x = prelu(x) </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.layer_num - <span class="number">2</span>):</span><br><span class="line">            x = self.linear_hidden[i](x)</span><br><span class="line">            x = F.tanh(x)</span><br><span class="line">            <span class="keyword">if</span> self.dropout:</span><br><span class="line">                x = F.dropout(x, training=self.training)</span><br><span class="line">        x = self.linear_out(x)</span><br><span class="line">        x = F.normalize(x, p=<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>先看<code>forward</code>函数。如果 feature_pre 为 True，则将输入数据 data 通过线性层 linear_pre 进行特征预处理。使用 PReLU（带参数的修正线性单元）激活函数对输入进行非线性变换。通过多个隐藏层进行数据的转换，每个隐藏层包含一个线性层和一个 tanh 激活函数。如果 dropout 为 True，在每个隐藏层后应用 dropout 操作，用于随机丢弃一部分神经元，以防止过拟合。通过线性层 linear_out 进行最终的输出，并对输出进行 L2 归一化操作。返回处理后的结果。</p><p>二、再来看一下具体提取出来的元神经网络部分的代码(以<code>user</code>部分的为例)</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Low rank matrix decomposition 低秩矩阵分解</span></span><br><span class="line">  metau1=self.mlp( tembedu). reshape(-<span class="number">1</span>,self.hide_dim,self.k)<span class="comment"># d*k</span></span><br><span class="line">  metau2=self.mlp1(tembedu). reshape(-<span class="number">1</span>,self.k,self.hide_dim)<span class="comment"># k*d</span></span><br><span class="line">  meta_biasu =(torch.mean( metau1,dim=<span class="number">0</span>))</span><br><span class="line">  meta_biasu1=(torch.mean( metau2,dim=<span class="number">0</span>))</span><br><span class="line">  low_weightu1=F.softmax( metau1 + meta_biasu, dim=<span class="number">1</span>)</span><br><span class="line">  low_weightu2=F.softmax( metau2 + meta_biasu1,dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><ul><li><p>利用生成的参数矩阵和非线性映射函数来构建我们的定制传输网络:</p><p>$\mathbf{E}<em>{uu}^M=\sigma(\mathbf{W}</em>{uu}^{M1}\mathbf{W}<em>{uu}^{M2}\mathbf{E}</em>{uu})$</p><p>其中，$\sigma(·)$代表<code>PReLU</code>激活函数,$\mathbf{E}_\text{uu }^M\in\mathbb{R}^{m\times d}$包含通过自定义映射转换的嵌入用户-用户社交视图的函数</p><p>ok,多说无益，再看一下具体的代码模块：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># The learned matrix as the weights of the transformed network</span></span><br><span class="line">    tembedus = (t.<span class="built_in">sum</span>(t.multiply( (auxiembedu).unsqueeze(-<span class="number">1</span>), low_weightu1), dim=<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># Equal to a two-layer linear network;</span></span><br><span class="line">    <span class="comment"># Ciao and Yelp data sets are plus gelu activation function</span></span><br><span class="line">    tembedus =  t.<span class="built_in">sum</span>(t.multiply((tembedus)  .unsqueeze(-<span class="number">1</span>), low_weightu2), dim=<span class="number">1</span>)</span><br><span class="line">    tembedis = (t.<span class="built_in">sum</span>(t.multiply((auxiembedi).unsqueeze(-<span class="number">1</span>), low_weighti1), dim=<span class="number">1</span>))</span><br><span class="line">    tembedis =  t.<span class="built_in">sum</span>(t.multiply((tembedis)  .unsqueeze(-<span class="number">1</span>), low_weighti2), dim=<span class="number">1</span>)</span><br><span class="line">    transfuEmbed = tembedus</span><br><span class="line">    transfiEmbed = tembedis</span><br></pre></td></tr></table></figure></li><li><p>然后利用定制的嵌入来增强从用户-项目交互中编码的用户嵌入。用户的融合过程通过以下加权求和进行:</p><p>$\mathbf{E}<em>u^F=\alpha_u<em>\mathbf{E}_u+(1-\alpha_u)</em>(\mathbf{E}_{uu}+\mathbf{E}</em>{uu}^M)$</p><p>其中$\alpha_{u}\in\mathbb{R}$表示控制用户-物品交互视图嵌入和用户-用户社交视图嵌入之间权重的超参数。在这里，用户-用户关系视图的原始嵌入也被用于更好的优化。$\mathbf{E}_{\boldsymbol{u}}^{F}\in\mathbb{R}^{\boldsymbol{m}\times d}$代表最终的embedding</p></li></ul><h3 id="4-4-用于增强的异质关系对比学习"><a href="#4-4-用于增强的异质关系对比学习" class="headerlink" title="4.4 用于增强的异质关系对比学习"></a>4.4 用于增强的异质关系对比学习</h3><h4 id="4-4-1-跨视图对比学习"><a href="#4-4-1-跨视图对比学习" class="headerlink" title="4.4.1 跨视图对比学习"></a>4.4.1 跨视图对比学习</h4><ul><li>设计了跨视图对比学习范式来增强具有自增强的异构关系学习的鲁棒性。具体来说，两个辅助视图($\mathbf{E}<em>{\boldsymbol{uu}}^{\boldsymbol{M}}$,$\mathbf{E}</em>{ii}^{\boldsymbol{M}}$)的嵌入与用户-项目交互视图($E_u$和$E_i$)。在这种设计下，辅助视图的嵌入作为有效的正则化来影响具有自监督信号的用户-物品交互建模。</li><li>为了通过考虑个性化的跨视图知识迁移来捕捉多样化的用户偏好，我们将个性化的跨视图知识迁移与对比学习集成在我们的推荐系统中。特别的，跨视图嵌入对齐在不同的表示视图之间以自适应的方式进行。</li><li>辅助视图特定的嵌入$E_{uu},E_{ii}$通过元网络生成的个性化映射函数进行处理，以生成个性化的辅助嵌入$\mathbf{E}<em>^M,\mathbf{E}</em>{ii}^M$</li></ul><h4 id="4-4-2-基于InfoNCE的对比度损失"><a href="#4-4-2-基于InfoNCE的对比度损失" class="headerlink" title="4.4.2 基于InfoNCE的对比度损失"></a>4.4.2 基于InfoNCE的对比度损失</h4><p>在异构图关系学习和跨视图元网络的帮助下，获得了用户和项目的两组embedding(用户：$\mathbf{E}<em>{\boldsymbol{uu}}^{\boldsymbol{M}},\mathbf{E}</em>{\boldsymbol{u}}$,物品：$\mathbf{E}_{ii}^M,\mathbf{E}_i$)</p><ul><li>使用基于infonce的两种表示视图之间的对比学习损失来增强我们的HGCL方法的用户/项目表示学习，如下所示:</li></ul><p>$\mathcal{L}<em>{cl}^u=\sum</em>{u\in\mathcal{V}<em>u}-\log\frac{\exp\left(s(\mathbf{e}</em>{uu}^M+\mathbf{e}<em>{uu},\mathbf{e}</em>{u})/\tau\right)}{\sum_{u^{\prime}\in\mathcal{V}<em>u}\exp\left(s(\mathbf{e}</em>{uu}^M+\mathbf{e}<em>{uu},\mathbf{e}</em>{u}^{\prime})/\tau\right)}$</p><p>其中$\mathbf{e}<em>{\boldsymbol{uu}}^M\in\mathbb{R}^d,\mathbf{e}</em>{\boldsymbol{u}}\in\mathbb{R}^d$分别是来自矩阵的嵌入向量$\mathbf{E}<em>{uu}^M,\mathbf{E}</em>{u}$. S(·) 表示相似度函数，可以是内积或余弦相似度，这里使用余弦相似度。τ代表温度系数，能够自动识别困难的负样本。</p><p>先来看一下相似度的代码函数展示：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">x1,x2</span>):</span></span><br><span class="line">    x1=F.normalize(x1,p=<span class="number">2</span>,dim=-<span class="number">1</span>)</span><br><span class="line">    x2=F.normalize(x2,p=<span class="number">2</span>,dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.multiply(x1,x2),<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>用于对输入的嵌入矩阵进行行和列的随机置换的代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">row_column_shuffle</span>(<span class="params">embedding</span>):</span></span><br><span class="line">    corrupted_embedding = embedding[:,torch.randperm(embedding.shape[<span class="number">1</span>])]</span><br><span class="line">    corrupted_embedding = corrupted_embedding[torch.randperm(embedding.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="keyword">return</span> corrupted_embedding</span><br></pre></td></tr></table></figure><p>完整的代码：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">metaregular</span>(<span class="params">self,em0,em,adj</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">row_column_shuffle</span>(<span class="params">embedding</span>):</span></span><br><span class="line">        corrupted_embedding = embedding[:,torch.randperm(embedding.shape[<span class="number">1</span>])]</span><br><span class="line">        corrupted_embedding = corrupted_embedding[torch.randperm(embedding.shape[<span class="number">0</span>])]</span><br><span class="line">        <span class="keyword">return</span> corrupted_embedding</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span>(<span class="params">x1,x2</span>):</span></span><br><span class="line">        x1=F.normalize(x1,p=<span class="number">2</span>,dim=-<span class="number">1</span>)</span><br><span class="line">        x2=F.normalize(x2,p=<span class="number">2</span>,dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.<span class="built_in">sum</span>(torch.multiply(x1,x2),<span class="number">1</span>)</span><br><span class="line">    user_embeddings = em</span><br><span class="line">    Adj_Norm =t.from_numpy(np.<span class="built_in">sum</span>(adj,axis=<span class="number">1</span>)).<span class="built_in">float</span>().cuda()</span><br><span class="line">    adj=self.sparse_mx_to_torch_sparse_tensor(adj)</span><br><span class="line">    edge_embeddings = torch.spmm(adj.cuda(),user_embeddings)/Adj_Norm</span><br><span class="line">    user_embeddings=em0</span><br><span class="line">    graph = torch.mean(edge_embeddings,<span class="number">0</span>)</span><br><span class="line">    pos   = score(user_embeddings,graph)</span><br><span class="line">    neg1  = score(row_column_shuffle(user_embeddings),graph)</span><br><span class="line">    global_loss = torch.mean(-torch.log(torch.sigmoid(pos-neg1)))</span><br><span class="line">    <span class="keyword">return</span> global_loss</span><br></pre></td></tr></table></figure><ol><li><code>Adj_Norm = t.from_numpy(np.sum(adj, axis=1)).float().cuda()</code>计算邻接矩阵<code>adj</code>每行的和，并转换为PyTorch张量，并将其转移到GPU上。</li><li><code>adj = self.sparse_mx_to_torch_sparse_tensor(adj)</code>将邻接矩阵<code>adj</code>转换为稀疏张量的表示形式。</li><li><code>edge_embeddings = torch.spmm(adj.cuda(), user_embeddings) / Adj_Norm</code>使用稀疏矩阵-向量乘法计算边的嵌入向量。首先，将邻接矩阵<code>adj</code>与用户嵌入矩阵<code>user_embeddings</code>相乘，然后除以<code>Adj_Norm</code>进行归一化。</li><li></li></ol><ul><li><p>相似的，可以获得物品方面的InfoNCE损失$\mathcal{L}_{\boldsymbol{c}\boldsymbol{l}}^i$</p></li><li><p>最后，总的对比损失$\mathcal{L}_{cl}=\alpha_1<em>\mathcal{L}_{cl}^u+\alpha_2</em>\mathcal{L}_{cl}^i$，$\alpha_1$和$\alpha_2$是权重调整的两个超参数</p></li></ul><h4 id="4-4-3-HGCL优化目标"><a href="#4-4-3-HGCL优化目标" class="headerlink" title="4.4.3 HGCL优化目标"></a>4.4.3 HGCL优化目标</h4><p>使用融合嵌入$\mathbf{E}<em>{\mathcal{U}}^F,\mathbf{E}</em>{\mathcal{i}}^F$,HGCL通过点积$\hat{y}<em>{u,i}=\mathbf{e}</em>{u}^{F\top}\mathbf{e}<em>{i}^{F}$预测用户$u$和项目$i$交互的可能性，$\hat{y}</em>{\boldsymbol{u},\boldsymbol{i}}$越大，意味着交互的可能性越大。</p><p>每个训练样本都配置了一个用户$u$,以及他接触过的正样本$i^+$,和一个未接触过的负样本$i^-$,对于每个训练样本，我们将预测得分最大化，如下:</p><p>$\mathcal{L}<em>{bpr}=\sum</em>{(u,i^+,i^-)\in O}-\ln(\operatorname{sigmoid}(\hat{y}<em>{u,i^+}-\hat{y}</em>{u,i^-}))+\lambda|\Theta|^2$</p><p>其中ln(·)和sigmoid(·)分别表示对数函数和sigmoid函数。λ代表确定正则化项权重的超参数。</p><p>将BPR损失函数与增强的横视对比学习损失相结合，整体训练损失为:</p><p>$\mathcal{L}=\mathcal{L}<em>{bpr}+\beta*\mathcal{L}</em>{cl}$</p><p>这部分的代码展示如下：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predictModel</span>(<span class="params">self,user, pos_i, neg_j, isTest=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> isTest:</span><br><span class="line">        pred_pos = t.<span class="built_in">sum</span>(user * pos_i, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> pred_pos</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        pred_pos = t.<span class="built_in">sum</span>(user * pos_i, dim=<span class="number">1</span>)</span><br><span class="line">        pred_neg = t.<span class="built_in">sum</span>(user * neg_j, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> pred_pos, pred_neg</span><br></pre></td></tr></table></figure><p>在主模型里面的代码部分：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># prediction</span></span><br><span class="line">            pred_pos, pred_neg = self.predictModel(self.ui_userEmbedall[user],  self.ui_itemEmbedall[item_i],  self.ui_itemEmbedall[item_j])</span><br><span class="line">            bpr_loss = - nn.LogSigmoid()(pred_pos - pred_neg).<span class="built_in">sum</span>()  </span><br><span class="line">            epoch_loss += bpr_loss.item()</span><br><span class="line">            regLoss = (t.norm(self.ui_userEmbedall[user])**<span class="number">2</span> + t.norm( self.ui_itemEmbedall[item_i])**<span class="number">2</span> + t.norm( self.ui_itemEmbedall[item_j])**<span class="number">2</span>) </span><br><span class="line">            loss = ((bpr_loss + regLoss * self.args.reg ) / self.args.batch) + ssl_loss*self.args.ssl_beta + metaregloss*self.args.metareg</span><br></pre></td></tr></table></figure><h3 id="4-5-模型复杂度分析"><a href="#4-5-模型复杂度分析" class="headerlink" title="4.5 模型复杂度分析"></a>4.5 模型复杂度分析</h3><p>不想关心这个</p><h2 id="5、模型评价"><a href="#5、模型评价" class="headerlink" title="5、模型评价"></a>5、模型评价</h2><h3 id="5-1-模型要解决的问题"><a href="#5-1-模型要解决的问题" class="headerlink" title="5.1 模型要解决的问题"></a>5.1 模型要解决的问题</h3><ol><li>与现有方法相比，HGCL的性能如何?</li><li>在我们的HGCL中加入关键组件以提高推荐性能是否有益?</li><li>HGCL在不同用户交互数据稀疏度的不同环境下的性</li><li>关键超参数如何影响模型性能?</li></ol><h3 id="5-2-实验设置"><a href="#5-2-实验设置" class="headerlink" title="5.2 实验设置"></a>5.2 实验设置</h3><p>数据集：Ciao，Epinions，Yelp</p><p>baseline：</p><p>超参数设置：</p></article><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://noionion-picture-bed.oss-cn-hangzhou.aliyuncs.com/deemo_for_cover/4.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdnjs.sourcegcdn.com/ajax/libs/social-share.js/1.0.16/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdnjs.sourcegcdn.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js" defer></script></div></div><div class="end is-center">end</div><div class="line is-center"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xigua2"></use></svg></div><div id="post-comment"><div class="comment-head is-center"><div class="comment-headline"><span>欢迎留言</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div></main><div id="content_rightside"><div id="rightside-toc"><div class="toc-box"><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1%E3%80%81%E6%91%98%E8%A6%81"><span class="toc-text">1、摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2%E3%80%81%E4%BB%8B%E7%BB%8D-INTRODUCTION"><span class="toc-text">2、介绍(INTRODUCTION)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3%E3%80%81%E7%9B%B8%E5%85%B3%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="toc-text">3、相关的工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%9F%BA%E4%BA%8Egnn%E7%9A%84%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-text">3.1 基于gnn的推荐系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-text">3.2 推荐系统中的对比学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%BC%82%E6%9E%84%E5%9B%BE%E5%AD%A6%E4%B9%A0"><span class="toc-text">3.3 异构图学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4%E3%80%81%E6%96%B9%E6%B3%95"><span class="toc-text">4、方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E7%AC%A6%E5%8F%B7%E8%A1%A8%E7%A4%BA"><span class="toc-text">4.1 符号表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-%E5%BC%82%E6%9E%84%E5%9B%BE%E5%85%B3%E7%B3%BB%E5%AD%A6%E4%B9%A0"><span class="toc-text">4.2 异构图关系学习</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-1-%E5%85%B3%E7%B3%BB%E6%84%9F%E7%9F%A5embedding%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-text">4.2.1 关系感知embedding初始化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-2-%E5%BC%82%E8%B4%A8%E6%B6%88%E6%81%AF%E4%BC%A0%E6%92%AD"><span class="toc-text">4.2.2 异质消息传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-2-3-%E5%BC%82%E6%9E%84%E4%BF%A1%E6%81%AF%E8%81%9A%E5%90%88"><span class="toc-text">4.2.3 异构信息聚合</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E8%B7%A8%E8%A7%86%E5%9B%BE%E5%85%83%E7%BD%91%E7%BB%9C"><span class="toc-text">4.3 跨视图元网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-%E5%85%83%E7%9F%A5%E8%AF%86%E6%8F%90%E5%8F%96"><span class="toc-text">4.3.1 元知识提取</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2%E4%B8%AA%E6%80%A7%E5%8C%96%E8%B7%A8%E8%A7%86%E8%A7%92%E7%9F%A5%E8%AF%86%E8%BF%81%E7%A7%BB"><span class="toc-text">4.3.2个性化跨视角知识迁移</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E7%94%A8%E4%BA%8E%E5%A2%9E%E5%BC%BA%E7%9A%84%E5%BC%82%E8%B4%A8%E5%85%B3%E7%B3%BB%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-text">4.4 用于增强的异质关系对比学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-1-%E8%B7%A8%E8%A7%86%E5%9B%BE%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-text">4.4.1 跨视图对比学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-2-%E5%9F%BA%E4%BA%8EInfoNCE%E7%9A%84%E5%AF%B9%E6%AF%94%E5%BA%A6%E6%8D%9F%E5%A4%B1"><span class="toc-text">4.4.2 基于InfoNCE的对比度损失</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-3-HGCL%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="toc-text">4.4.3 HGCL优化目标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E6%A8%A1%E5%9E%8B%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-text">4.5 模型复杂度分析</span></a></li></ol><li class="toc-item toc-level-2"><a class="toc-link" href="#5%E3%80%81%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7"><span class="toc-text">5、模型评价</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E6%A8%A1%E5%9E%8B%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-text">5.1 模型要解决的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-text">5.2 实验设置</span></a></li></ol></li></div></div></div><div id="rightside-button"><button id="rightside-go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div></div><footer id="footer"><div class="wordcount"><span>猹居然写了 53.2k 字</span><br><span>好像写完一本 埃克苏佩里 的 《小王子》 了啊</span></div><div class="footer-content"><a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span style="padding:.4rem">hexo</span></a><a><i class="fas fa-heart"></i></a><a href="https://butterfly.js.org/" target="_blank" rel="nofollow noopener"><span style="padding:.4rem">butterfly</span></a><div style="font-size:.7rem"><span id="timeDate">载入天数...</span><span> </span><span id="times">载入时分秒...</span><script src="/js/add/duration.js"></script></div></div><div class="statistics"><span id="site_uv">有 <span id="busuanzi_value_site_uv"></span><span> 人光顾过猹的小窝</span></span><span id="site_pv"><span>共 </span><span id="busuanzi_value_site_pv"></span><span> 次在这里摘了个瓜</span></span></div></footer></div><div id="rightside"></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typeset();else{window.MathJax={loader:{source:{"[tex]/amsCd":"[tex]/amscd"}},tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},options:{renderActions:{findScript:[10,t=>{for(const s of document.querySelectorAll('script[type^="math/tex"]')){var e=!!s.type.match(/; *mode=display/),e=new t.options.MathItem(s.textContent,t.inputJax[0],e),a=document.createTextNode("");s.parentNode.replaceChild(a,s),e.start={node:a,delim:"",n:0},e.end={node:a,delim:"",n:0},t.math.push(e)}},""],addClass:[200,()=>{document.querySelectorAll("mjx-container:not([display='true']").forEach(t=>{t=t.parentNode;t.classList.contains("has-jax")||t.classList.add("mathjax-overflow")})},"",!1]}}};const a=document.createElement("script");a.src="https://cdnjs.sourcegcdn.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.min.js",a.id="MathJax-script",a.async=!0,document.head.appendChild(a)}</script><link rel="stylesheet" type="text/css" href="https://cdnjs.sourcegcdn.com/ajax/libs/KaTeX/0.15.3/katex.min.css"><script src="https://cdnjs.sourcegcdn.com/ajax/libs/KaTeX/0.15.3/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdnjs.sourcegcdn.com/ajax/libs/KaTeX/0.15.3/contrib/copy-tex.min.css"><script>document.querySelectorAll("#article-container span.katex-display").forEach(a=>{btf.wrap(a,"div","","katex-wrap")})</script><script>(()=>{const t=document.getElementById("twikoo-count"),n=()=>{let o={el:"#twikoo-wrap",envId:"https://twikoo.noionion.cn",region:""};twikoo.init(o)},e=()=>{twikoo.getCommentsCount({envId:"https://twikoo.noionion.cn",region:"",urls:[window.location.pathname],includeReply:!1}).then(function(o){t.innerText=o[0].count}).catch(function(o){console.error(o)})},o=(o=!1)=>{"object"==typeof twikoo?(n(),o&&t&&setTimeout(e,0)):getScript("https://cdnjs.sourcegcdn.com/ajax/libs/twikoo/1.6.7/twikoo.all.min.js").then(()=>{n(),o&&t&&setTimeout(e,0)})};btf.loadComment(document.getElementById("twikoo-wrap"),o)})()</script></div><script async src="//at.alicdn.com/t/font_2749059_1lswi5j6yqg.js"></script><script src="/js/add/nav.js"></script><script src="/js/add/leftsidemenu.js"></script><script src="https://cdn1.tianli0.top/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!1,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script data-pjax>function butterfly_footer_beautify_injector_config(){var e=document.getElementById("footer-wrap");console.log("已挂载butterfly_footer_beautify"),e.insertAdjacentHTML("beforeend",'<div id="ghbdages" style="overflow:hidden;max-height:180px;height:auto;text-align:center;margin-top:10px"><div class="swiper-wrapper"><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v5.3.0"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v3.7.0-b2"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://www.sourcegcdn.com/" style="margin-inline:5px" title="本站使用Source Global CDN为部分静态资源提供CDN加速"><img src="https://img.shields.io/badge/CDN-sourcegcdn-orange?style=flat&amp;logo=Apache%20RocketMQ" alt=""/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px" title="本站使用JsDelivr仅用于访问部分静态资源"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站项目由Github托管"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></div></div></div><style>a.github-badge:hover:before {display:none}</style>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_footer_beautify_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-footer-beautify/lib/swiperbdage_init_js.min.js"></script></body></html>